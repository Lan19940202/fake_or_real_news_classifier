{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news = pd.read_csv('fake_or_real_news.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "8476                        You Can Smell Hillary’s Fear   \n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "3608         Kerry to go to Paris in gesture of sympathy   \n",
       "10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "875     The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                    text label  \n",
       "8476   Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "10294  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "3608   U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "10142  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "875    It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6335 entries, 8476 to 4330\n",
      "Data columns (total 3 columns):\n",
      "title    6335 non-null object\n",
      "text     6335 non-null object\n",
      "label    6335 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 198.0+ KB\n"
     ]
    }
   ],
   "source": [
    "news.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>6335</td>\n",
       "      <td>6256</td>\n",
       "      <td>OnPolitics | 's politics blog</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>6335</td>\n",
       "      <td>6060</td>\n",
       "      <td>Killing Obama administration rules, dismantlin...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>6335</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "      <td>3171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count unique                                                top  freq\n",
       "title  6335   6256                      OnPolitics | 's politics blog     5\n",
       "text   6335   6060  Killing Obama administration rules, dismantlin...    58\n",
       "label  6335      2                                               REAL  3171"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    3171\n",
       "FAKE    3164\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two classes are basically balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Convert label from string to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le2 = LabelEncoder()\n",
    "news['binary_label']=le2.fit_transform(news['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news = news.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary’s Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  binary_label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE             0  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE             0  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL             1  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE             0  \n",
       "4  It's primary day in New York and front-runners...  REAL             1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(news['text'], news.binary_label , random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Features and Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 default stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.840\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.96      0.70      0.81       769\n",
      "       REAL       0.77      0.97      0.86       815\n",
      "\n",
      "avg / total       0.86      0.84      0.84      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform dataset\n",
    "tfidf_vectorizer_default = TfidfVectorizer(stop_words='english', max_df=0.7) \n",
    "tfidf_train_default = tfidf_vectorizer_default.fit_transform(X_train) \n",
    "tfidf_test_default = tfidf_vectorizer_default.transform(X_test)\n",
    "\n",
    "# Build model\n",
    "clf_default = MultinomialNB() \n",
    "clf_default.fit(tfidf_train_default, y_train)\n",
    "\n",
    "# Validate\n",
    "pred_default = clf_default.predict(tfidf_test_default)\n",
    "score_default = accuracy_score(y_test, pred_default)\n",
    "print (\"accuracy:   %0.3f\" % score_default)\n",
    "print(classification_report(y_test, pred_default, target_names=['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 stop words down load from http://www.lextek.com/manuals/onix/stopwords1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the stopwords file from the website\n",
    "import requests\n",
    "import bs4\n",
    "\n",
    "res = requests.get('http://www.lextek.com/manuals/onix/stopwords1.html')\n",
    "soup = bs4.BeautifulSoup(res.text,\"lxml\")\n",
    "stop_words=[tag.text for tag in soup.select('pre')]\n",
    "stop_words=[l.split('\\n\\n') for l in stop_words]\n",
    "stop_words=stop_words[0][6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.847\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.95      0.72      0.82       769\n",
      "       REAL       0.79      0.97      0.87       815\n",
      "\n",
      "avg / total       0.87      0.85      0.84      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform dataset\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words, max_df=0.7) \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Build model\n",
    "clf = MultinomialNB() \n",
    "clf.fit(tfidf_train, y_train)\n",
    "\n",
    "# Validate\n",
    "pred = clf.predict(tfidf_test)\n",
    "score = accuracy_score(y_test, pred)\n",
    "print (\"accuracy:   %0.3f\" % score)\n",
    "print(classification_report(y_test, pred, target_names=['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the recall score of FAKE calss and the accuracy of the model all improved, the stop words file down loaded is more suitable for the dataset used in this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Improve the number of gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ngram_range=(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.903\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.98      0.82      0.89       769\n",
      "       REAL       0.85      0.99      0.91       815\n",
      "\n",
      "avg / total       0.91      0.90      0.90      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform dataset\n",
    "tfidf_vectorizer_2 = TfidfVectorizer(stop_words=stop_words, ngram_range=(2,2) ,max_df=0.7) \n",
    "tfidf_train_2 = tfidf_vectorizer_2.fit_transform(X_train) \n",
    "tfidf_test_2 = tfidf_vectorizer_2.transform(X_test)\n",
    "\n",
    "# Build model\n",
    "clf_2 = MultinomialNB() \n",
    "clf_2.fit(tfidf_train_2, y_train)\n",
    "\n",
    "# Validate\n",
    "pred_2 = clf_2.predict(tfidf_test_2)\n",
    "score_2 = accuracy_score(y_test, pred_2)\n",
    "print (\"accuracy:   %0.3f\" % score_2)\n",
    "print(classification_report(y_test, pred_2, target_names=['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ngram_range=(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.924\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.95      0.90      0.92       769\n",
      "       REAL       0.91      0.95      0.93       815\n",
      "\n",
      "avg / total       0.93      0.92      0.92      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform dataset\n",
    "tfidf_vectorizer_3 = TfidfVectorizer(stop_words=stop_words, ngram_range=(3,3) ,max_df=0.7) \n",
    "tfidf_train_3 = tfidf_vectorizer_3.fit_transform(X_train) \n",
    "tfidf_test_3 = tfidf_vectorizer_3.transform(X_test)\n",
    "\n",
    "# Build model\n",
    "clf_3 = MultinomialNB() \n",
    "clf_3.fit(tfidf_train_3, y_train)\n",
    "\n",
    "# Validate\n",
    "pred_3 = clf_3.predict(tfidf_test_3)\n",
    "score_3 = accuracy_score(y_test, pred_3)\n",
    "print (\"accuracy:   %0.3f\" % score_3)\n",
    "print(classification_report(y_test, pred_3, target_names=['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy and recall score improve a lot after the number of gram improved;\n",
    "* However, when the ngram_range grows larger, the model need too long time to run. So I choose ngram_range=(3,3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Tuning parameters for MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.8}\n",
      "Best cross-validation Accuracy: 0.8272\n",
      "Best estimator:\n",
      "MultinomialNB(alpha=0.8, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "clf_3_tune = MultinomialNB() \n",
    "\n",
    "para = {'alpha': np.arange(0.1,1.1,0.1)}\n",
    "\n",
    "kfold=KFold(n_splits=5, random_state=10)\n",
    "\n",
    "clf_3_grid = GridSearchCV(clf_3_tune, para, cv=kfold, scoring= 'accuracy')\n",
    "\n",
    "#Fitting\n",
    "clf_3_grid.fit(tfidf_train_3, y_train)\n",
    "\n",
    "#Printing reports\n",
    "print(\"Best Parameters: {}\".format(clf_3_grid.best_params_))\n",
    "print(\"Best cross-validation Accuracy: {:.4f}\".format(clf_3_grid.best_score_))\n",
    "print(\"Best estimator:\\n{}\".format(clf_3_grid.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.5 Build the model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.925\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.95      0.90      0.92       769\n",
      "       REAL       0.91      0.95      0.93       815\n",
      "\n",
      "avg / total       0.93      0.92      0.92      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform dataset\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words, ngram_range=(3,3) ,max_df=0.7) \n",
    "tfidf_train = tfidf_vectorizer_3.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer_3.transform(X_test)\n",
    "\n",
    "# Build model\n",
    "clf_tfidf = MultinomialNB(alpha=0.8) \n",
    "clf_tfidf.fit(tfidf_train, y_train)\n",
    "\n",
    "# Validate\n",
    "pred_tfidf = clf_tfidf.predict(tfidf_test)\n",
    "score_tfidf = accuracy_score(y_test, pred_tfidf)\n",
    "print (\"accuracy:   %0.3f\" % score_tfidf)\n",
    "print(classification_report(y_test, pred_tfidf, target_names=['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 CountVectorizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Build models with different stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* stop_words='english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.888\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.92      0.84      0.88       769\n",
      "       REAL       0.86      0.93      0.90       815\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train) \n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "clf2 = MultinomialNB() \n",
    "clf2.fit(count_train, y_train)\n",
    "pred2 = clf2.predict(count_test)\n",
    "\n",
    "score = accuracy_score(y_test, pred2)\n",
    "print (\"accuracy:   %0.3f\" % score)\n",
    "print(classification_report(y_test, pred2, target_names=['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* stop_words=stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.887\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.92      0.84      0.88       769\n",
      "       REAL       0.86      0.93      0.89       815\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "count_train = count_vectorizer.fit_transform(X_train) \n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "clf2 = MultinomialNB() \n",
    "clf2.fit(count_train, y_train)\n",
    "pred2 = clf2.predict(count_test)\n",
    "\n",
    "score = accuracy_score(y_test, pred2)\n",
    "print (\"accuracy:   %0.3f\" % score)\n",
    "print(classification_report(y_test, pred2, target_names=['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the preformance difference between the two models is small, I still choose to use the stop words down loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Improve the number of 'ngram_range'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.910\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.98      0.83      0.90       769\n",
      "       REAL       0.86      0.98      0.92       815\n",
      "\n",
      "avg / total       0.92      0.91      0.91      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer_2 = CountVectorizer(stop_words=stop_words, ngram_range=(2, 2))\n",
    "count_train_2 = count_vectorizer_2.fit_transform(X_train) \n",
    "count_test_2 = count_vectorizer_2.transform(X_test)\n",
    "\n",
    "clf_2 = MultinomialNB() \n",
    "clf_2.fit(count_train_2, y_train)\n",
    "pred_2 = clf_2.predict(count_test_2)\n",
    "\n",
    "score_2 = accuracy_score(y_test, pred_2)\n",
    "print (\"accuracy:   %0.3f\" % score_2)\n",
    "print(classification_report(y_test, pred_2, target_names=['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.924\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.96      0.88      0.92       769\n",
      "       REAL       0.90      0.96      0.93       815\n",
      "\n",
      "avg / total       0.93      0.92      0.92      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer_3 = CountVectorizer(stop_words=stop_words, ngram_range=(3, 3))\n",
    "count_train_3 = count_vectorizer_3.fit_transform(X_train) \n",
    "count_test_3 = count_vectorizer_3.transform(X_test)\n",
    "\n",
    "clf_3 = MultinomialNB() \n",
    "clf_3.fit(count_train_3, y_train)\n",
    "pred_3 = clf_3.predict(count_test_3)\n",
    "\n",
    "score_3 = accuracy_score(y_test, pred_3)\n",
    "print (\"accuracy:   %0.3f\" % score_3)\n",
    "print(classification_report(y_test, pred_3, target_names=['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Apply grid search to find the best 'alpha'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 1.0}\n",
      "Best cross-validation Accuracy: 0.7649\n",
      "Best estimator:\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "clf_tune_count = MultinomialNB() \n",
    "\n",
    "para = {'alpha': np.arange(0.1,1.1,0.1)}\n",
    "\n",
    "kfold=KFold(n_splits=5, random_state=10)\n",
    "\n",
    "clf_grid_count = GridSearchCV(clf_tune_count, para, cv=kfold, scoring= 'accuracy')\n",
    "\n",
    "#Fitting\n",
    "clf_grid_count.fit(count_train_3, y_train)\n",
    "\n",
    "#Printing reports\n",
    "print(\"Best Parameters: {}\".format(clf_grid_count.best_params_))\n",
    "print(\"Best cross-validation Accuracy: {:.4f}\".format(clf_grid_count.best_score_))\n",
    "print(\"Best estimator:\\n{}\".format(clf_grid_count.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Build the model with best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.924\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.96      0.88      0.92       769\n",
      "       REAL       0.90      0.96      0.93       815\n",
      "\n",
      "avg / total       0.93      0.92      0.92      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=stop_words, ngram_range=(3, 3))\n",
    "count_train = count_vectorizer.fit_transform(X_train) \n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "clf_count = MultinomialNB(alpha=1.0) \n",
    "clf_count.fit(count_train, y_train)\n",
    "pred_count = clf_3.predict(count_test)\n",
    "\n",
    "score_count = accuracy_score(y_test, pred_count)\n",
    "print (\"accuracy:   %0.3f\" % score_count)\n",
    "print(classification_report(y_test, pred_count, target_names=['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.925\n",
      "TfidfVectorizer:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.95      0.90      0.92       769\n",
      "       REAL       0.91      0.95      0.93       815\n",
      "\n",
      "avg / total       0.93      0.92      0.92      1584\n",
      " \n",
      "\n",
      "\n",
      "accuracy:   0.924\n",
      "CountVectorizer:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.96      0.88      0.92       769\n",
      "       REAL       0.90      0.96      0.93       815\n",
      "\n",
      "avg / total       0.93      0.92      0.92      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"accuracy:   %0.3f\" % score_tfidf)\n",
    "print('TfidfVectorizer:\\n\\n',classification_report(y_test, pred_tfidf, target_names=['FAKE', 'REAL']),'\\n\\n')\n",
    "print (\"accuracy:   %0.3f\" % score_count)\n",
    "print('CountVectorizer:\\n\\n',classification_report(y_test, pred_count, target_names=['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With naive bayes classifier, TfidfVectorizer feature extraction is more suitable for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
